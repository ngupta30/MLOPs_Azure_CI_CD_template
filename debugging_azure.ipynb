{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "conda info --envs"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "# conda environments:\n#\nbase                     /anaconda\nazureml_py310_sdkv2      /anaconda/envs/azureml_py310_sdkv2\nazureml_py38             /anaconda/envs/azureml_py38\nazureml_py38_PT_TF       /anaconda/envs/azureml_py38_PT_TF\ninference_env            /anaconda/envs/inference_env\n\n\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 1,
      "metadata": {},
      "id": "44cb4b27-8720-4c03-98b4-521d4d39957f"
    },
    {
      "cell_type": "code",
      "source": [
        "!source activate inference_env"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {},
      "id": "9ee85deb-93b3-4871-922b-880705e228e2"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.workspace import Workspace\n",
        "from azureml.core.dataset import Dataset\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {},
      "id": "a9db586e-2f1e-4d40-a922-38fbf8cdc2f9"
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {},
      "id": "a16ab8e8-3230-44d8-ad62-b9cc38251f7b"
    },
    {
      "cell_type": "code",
      "source": [
        "ws.datasets"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "{'titatnic_dataset': DatasetRegistration(id='94c42d38-6d85-49b1-814c-c51b5ffac997', name='titatnic_dataset', version=1, description='', tags={})}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {},
      "id": "0e67252b-81af-4e71-8d44-1e3b1ab690a0"
    },
    {
      "cell_type": "code",
      "source": [
        "ws.models"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "{'titanic_model': Model(workspace=Workspace.create(name='titanic-aml-v1', subscription_id='ffe8e859-0cfb-4c23-8708-291600dadedf', resource_group='titanic-rg-v1'), name=titanic_model, id=titanic_model:9, version=9, tags={'data': 'titanic', 'model': 'classification'}, properties={})}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {},
      "id": "c9ca48c3-6d36-4bb0-9db0-efc7b98ffbe9"
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {},
      "id": "7fc0fd59-4a10-45c4-8072-c04397c935b9"
    },
    {
      "cell_type": "code",
      "source": [
        "#m1 = joblib.load(ws.models['titanic_model'])"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {},
      "id": "d4bebb4c-16f5-4078-bf70-dbeb0d870fe5"
    },
    {
      "cell_type": "code",
      "source": [
        "## Use the below to prevent the 'No usable environment found' error\n",
        "\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.automl.core.shared import constants\n",
        "\n",
        "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"scoringConfig.yml\")\n",
        "myenv"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "No Python version provided, defaulting to \"3.8.13\"\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "{\n    \"assetId\": null,\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20221010.v1\",\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"buildContext\": null,\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": \"2g\"\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": \"myenv\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"dependencies\": [\n                \"python=3.8.13\",\n                \"pip=21.2.4\",\n                {\n                    \"pip\": [\n                        \"azureml-sdk\",\n                        \"azureml-defaults\",\n                        \"scikit-learn\",\n                        \"inference-schema[numpy-support]\",\n                        \"lightgbm\",\n                        \"LightGBM\",\n                        \"joblib\"\n                    ]\n                }\n            ],\n            \"name\": \"inference_env\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": false\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": null\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {},
      "id": "f44f1cce-80ea-4e08-9675-3a47511ac1c3"
    },
    {
      "cell_type": "code",
      "source": [
        "#model = ws.models['titanic_model']\n",
        "from azureml.core.model import Model\n",
        "model = Model(ws, name=\"titanic_model\", version=9)\n",
        "model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='titanic-aml-v1', subscription_id='ffe8e859-0cfb-4c23-8708-291600dadedf', resource_group='titanic-rg-v1'), name=titanic_model, id=titanic_model:9, version=9, tags={'data': 'titanic', 'model': 'classification'}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {},
      "id": "e63290bf-f723-4523-b1b3-5470639cfc2c"
    },
    {
      "cell_type": "code",
      "source": [
        " ws.models"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "{'titanic_model': Model(workspace=Workspace.create(name='titanic-aml-v1', subscription_id='ffe8e859-0cfb-4c23-8708-291600dadedf', resource_group='titanic-rg-v1'), name=titanic_model, id=titanic_model:9, version=9, tags={'data': 'titanic', 'model': 'classification'}, properties={})}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {},
      "id": "2f4a5ba7-e634-4ec5-b9e4-a1ccc1244130"
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.environment import Environment\n",
        "\n",
        "inference_config = InferenceConfig(entry_script='score.py', environment=myenv)\n",
        "\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
        "                                               memory_gb = 1, \n",
        "                                               description = 'Titanic classification service')\n",
        "\n",
        "aci_service_name = 'titanic-all1'\n",
        "print(aci_service_name)\n",
        "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "titanic-all1\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/tmp/ipykernel_90311/373667320.py:15: FutureWarning: azureml.core.model:\nTo leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \nplease refer to respective documentations \nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoint-sdk-v2 /\nhttps://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \nFor more information on migration, see https://aka.ms/acimoemigration. \nTo disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n  aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\nRunning\n2022-12-19 12:17:55+00:00 Creating Container Registry if not exists.\n2022-12-19 12:17:55+00:00 Registering the environment.\n2022-12-19 12:17:56+00:00 Use the existing image.\n2022-12-19 12:17:56+00:00 Generating deployment configuration.\n2022-12-19 12:17:57+00:00 Submitting deployment to compute.\n2022-12-19 12:18:00+00:00 Checking the status of deployment titanic-all1..\n2022-12-19 12:19:42+00:00 Checking the status of inference endpoint titanic-all1.\nFailed\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: ab95e457-0955-47fe-b6bb-c152b9ba96b5\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-12-19T12:21:05.342Z\",\"exitCode\":111,\"finishTime\":\"2022-12-19T12:21:17.527Z\",\"detailStatus\":\"Error\"}\n\"Events\": null\n\"\n    }\n  ]\n}\n\n"
        },
        {
          "output_type": "error",
          "ename": "WebserviceException",
          "evalue": "WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: ab95e457-0955-47fe-b6bb-c152b9ba96b5\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-12-19T12:21:05.342Z\",\"exitCode\":111,\"finishTime\":\"2022-12-19T12:21:17.527Z\",\"detailStatus\":\"Error\"}\n\"Events\": null\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: ab95e457-0955-47fe-b6bb-c152b9ba96b5\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2022-12-19T12:21:05.342Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2022-12-19T12:21:17.527Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\": null\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [19], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(aci_service_name)\n\u001b[1;32m     15\u001b[0m aci_service \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mdeploy(ws, aci_service_name, [model], inference_config, aciconfig)\n\u001b[0;32m---> 16\u001b[0m \u001b[43maci_service\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_deployment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(aci_service\u001b[38;5;241m.\u001b[39mstate)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/webservice.py:918\u001b[0m, in \u001b[0;36mWebservice.wait_for_deployment\u001b[0;34m(self, show_output, timeout_sec)\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logs_response:\n\u001b[1;32m    916\u001b[0m             logs_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrent sub-operation type not known, more logs unavailable.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 918\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebserviceException(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mService deployment polling reached non-successful terminal state, current \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    919\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice state: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    920\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOperation ID: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    921\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    922\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    923\u001b[0m                                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_operation_endpoint\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    924\u001b[0m                                               logs_response, format_error_response), logger\u001b[38;5;241m=\u001b[39mmodule_logger)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m service creation operation finished, operation \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_webservice_type,\n\u001b[1;32m    926\u001b[0m                                                                           operation_state))\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WebserviceException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Service deployment polling reached non-successful terminal state, current service state: Failed\nOperation ID: ab95e457-0955-47fe-b6bb-c152b9ba96b5\nMore information can be found using '.get_logs()'\nError:\n{\n  \"code\": \"AciDeploymentFailed\",\n  \"statusCode\": 400,\n  \"message\": \"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\",\n  \"details\": [\n    {\n      \"code\": \"CrashLoopBackOff\",\n      \"message\": \"Your container application crashed. This may be caused by errors in your scoring file's init() function.\n\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\n\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\"\n    },\n    {\n      \"code\": \"AciDeploymentFailed\",\n      \"message\": \"Your container application crashed. Please follow the steps to debug:\n\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\n\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\n\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\n\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\n\"RestartCount\": 3\n\"CurrentState\": {\"state\":\"Waiting\",\"startTime\":null,\"exitCode\":null,\"finishTime\":null,\"detailStatus\":\"CrashLoopBackOff: Back-off restarting failed\"}\n\"PreviousState\": {\"state\":\"Terminated\",\"startTime\":\"2022-12-19T12:21:05.342Z\",\"exitCode\":111,\"finishTime\":\"2022-12-19T12:21:17.527Z\",\"detailStatus\":\"Error\"}\n\"Events\": null\n\"\n    }\n  ]\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Service deployment polling reached non-successful terminal state, current service state: Failed\\nOperation ID: ab95e457-0955-47fe-b6bb-c152b9ba96b5\\nMore information can be found using '.get_logs()'\\nError:\\n{\\n  \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n  \\\"statusCode\\\": 400,\\n  \\\"message\\\": \\\"Aci Deployment failed with exception: Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\",\\n  \\\"details\\\": [\\n    {\\n      \\\"code\\\": \\\"CrashLoopBackOff\\\",\\n      \\\"message\\\": \\\"Your container application crashed. This may be caused by errors in your scoring file's init() function.\\n\\t1. Please check the logs for your container instance: titanic-all1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs.\\n\\t2. You can interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t3. You can also try to run image titanicv1amlcr.azurecr.io/azureml/azureml_82455aa012066c116bfeb275ff99e1ba locally. Please refer to https://aka.ms/debugimage#service-launch-fails for more information.\\\"\\n    },\\n    {\\n      \\\"code\\\": \\\"AciDeploymentFailed\\\",\\n      \\\"message\\\": \\\"Your container application crashed. Please follow the steps to debug:\\n\\t1. From the AML SDK, you can run print(service.get_logs()) if you have service object to fetch the logs. Please refer to https://aka.ms/debugimage#dockerlog for more information.\\n\\t2. If your container application crashed. This may be caused by errors in your scoring file's init() function. You can try debugging locally first. Please refer to https://aka.ms/debugimage#debug-locally for more information.\\n\\t3. You can also interactively debug your scoring file locally. Please refer to https://docs.microsoft.com/azure/machine-learning/how-to-debug-visual-studio-code#debug-and-troubleshoot-deployments for more information.\\n\\t4. View the diagnostic events to check status of container, it may help you to debug the issue.\\n\\\"RestartCount\\\": 3\\n\\\"CurrentState\\\": {\\\"state\\\":\\\"Waiting\\\",\\\"startTime\\\":null,\\\"exitCode\\\":null,\\\"finishTime\\\":null,\\\"detailStatus\\\":\\\"CrashLoopBackOff: Back-off restarting failed\\\"}\\n\\\"PreviousState\\\": {\\\"state\\\":\\\"Terminated\\\",\\\"startTime\\\":\\\"2022-12-19T12:21:05.342Z\\\",\\\"exitCode\\\":111,\\\"finishTime\\\":\\\"2022-12-19T12:21:17.527Z\\\",\\\"detailStatus\\\":\\\"Error\\\"}\\n\\\"Events\\\": null\\n\\\"\\n    }\\n  ]\\n}\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {},
      "id": "6d365b94-c310-4564-ad2a-db4505309b27"
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install azure-ai-ml"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {},
      "id": "0a974ce0-70c6-496c-976a-a79517b05160"
    },
    {
      "cell_type": "code",
      "source": [
        "os.getenv(\"AZUREML_MODEL_DIR\")"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {},
      "id": "c79b3d2c-c1cb-4a4d-9864-3cf13294997c"
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "394ea7df-72e6-4ce1-a07c-68b41cee7ff2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}